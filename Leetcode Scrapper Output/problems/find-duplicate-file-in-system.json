{"tags": [{"duration": "0 - 6 months", "companies": [["0 - 6 months", "Dropbox\n2"], ["0 - 6 months", "Amazon\n2"]]}, {"duration": "6 months - 1 year", "companies": [["6 months - 1 year", "Google\n2"]]}, {"duration": "1 year - 2 years", "companies": [["1 year - 2 years", "Microsoft\n4"], ["1 year - 2 years", "Apple\n3"], ["1 year - 2 years", "Snapchat\n2"], ["1 year - 2 years", "Facebook\n2"], ["1 year - 2 years", "Tableau\n2"], ["1 year - 2 years", "Spotify\n2"], ["1 year - 2 years", "Uber\n2"]]}], "problem": "<p>Given a list <code>paths</code> of directory info, including the directory path, and all the files with contents in this directory, return <em>all the duplicate files in the file system in terms of their paths</em>. You may return the answer in <strong>any order</strong>.</p>\n\n<p>A group of duplicate files consists of at least two files that have the same content.</p>\n\n<p>A single directory info string in the input list has the following format:</p>\n\n<ul>\n\t<li><code>\"root/d1/d2/.../dm f1.txt(f1_content) f2.txt(f2_content) ... fn.txt(fn_content)\"</code></li>\n</ul>\n\n<p>It means there are <code>n</code> files <code>(f1.txt, f2.txt ... fn.txt)</code> with content <code>(f1_content, f2_content ... fn_content)</code> respectively in the directory \"<code>root/d1/d2/.../dm\"</code>. Note that <code>n &gt;= 1</code> and <code>m &gt;= 0</code>. If <code>m = 0</code>, it means the directory is just the root directory.</p>\n\n<p>The output is a list of groups of duplicate file paths. For each group, it contains all the file paths of the files that have the same content. A file path is a string that has the following format:</p>\n\n<ul>\n\t<li><code>\"directory_path/file_name.txt\"</code></li>\n</ul>\n\n<p>&nbsp;</p>\n<p><strong class=\"example\">Example 1:</strong></p>\n<pre><strong>Input:</strong> paths = [\"root/a 1.txt(abcd) 2.txt(efgh)\",\"root/c 3.txt(abcd)\",\"root/c/d 4.txt(efgh)\",\"root 4.txt(efgh)\"]\n<strong>Output:</strong> [[\"root/a/2.txt\",\"root/c/d/4.txt\",\"root/4.txt\"],[\"root/a/1.txt\",\"root/c/3.txt\"]]\n</pre><p><strong class=\"example\">Example 2:</strong></p>\n<pre><strong>Input:</strong> paths = [\"root/a 1.txt(abcd) 2.txt(efgh)\",\"root/c 3.txt(abcd)\",\"root/c/d 4.txt(efgh)\"]\n<strong>Output:</strong> [[\"root/a/2.txt\",\"root/c/d/4.txt\"],[\"root/a/1.txt\",\"root/c/3.txt\"]]\n</pre>\n<p>&nbsp;</p>\n<p><strong>Constraints:</strong></p>\n\n<ul>\n\t<li><code>1 &lt;= paths.length &lt;= 2 * 10<sup>4</sup></code></li>\n\t<li><code>1 &lt;= paths[i].length &lt;= 3000</code></li>\n\t<li><code>1 &lt;= sum(paths[i].length) &lt;= 5 * 10<sup>5</sup></code></li>\n\t<li><code>paths[i]</code> consist of English letters, digits, <code>'/'</code>, <code>'.'</code>, <code>'('</code>, <code>')'</code>, and <code>' '</code>.</li>\n\t<li>You may assume no files or directories share the same name in the same directory.</li>\n\t<li>You may assume each given directory info represents a unique directory. A single blank space separates the directory path and file info.</li>\n</ul>\n\n<p>&nbsp;</p>\n<p><strong>Follow up:</strong></p>\n\n<ul>\n\t<li>Imagine you are given a real file system, how will you search files? DFS or BFS?</li>\n\t<li>If the file content is very large (GB level), how will you modify your solution?</li>\n\t<li>If you can only read the file by 1kb each time, how will you modify your solution?</li>\n\t<li>What is the time complexity of your modified solution? What is the most time-consuming part and memory-consuming part of it? How to optimize?</li>\n\t<li>How to make sure the duplicated files you find are not false positive?</li>\n</ul>\n", "relatedTopics": ["Array", "Hash Table", "String"], "similarQuestions": [{"questionName": "Delete Duplicate Folders in System", "difficulty": "Hard"}], "problemName": "find-duplicate-file-in-system"}